{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running plantseg\n",
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.tasks.io_tasks import import_image_task\n",
    "from pathlib import Path\n",
    "\n",
    "# Transform image into PlantsegImage\n",
    "path=Path(r\"E:\\PROJECTS-01\\Adrian\\Bachelor_project\\Raw_data\\t0001_ch1.tif\")\n",
    "semantic_type=\"raw\" # options are 'raw', 'segmentation' and 'prediction'\n",
    "stack_layout= \"ZYX\" # options are 'ZYX', 'YX', '2D_time'\n",
    "image=import_image_task(input_path=path,semantic_type=semantic_type,stack_layout=stack_layout)\n",
    "raw_image=image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.functionals.dataprocessing.dataprocessing import image_gaussian_smoothing,scale_image_to_voxelsize\n",
    "from plantseg.tasks.dataprocessing_tasks import image_cropping_task,set_voxel_size_task,gaussian_smoothing_task\n",
    "import numpy as np\n",
    "# Cropping, change intervals to what you need\n",
    "#[77:195,437:1446,654:]\n",
    "rectangle_bi= np.array([\n",
    "    [77, 437, 654],  # Premier coin (z, y, x)\n",
    "    [77, 1446, 654],  # Deuxième coin (z, y, x)\n",
    "    [77,1446 ,2304]   # Troisième coin (z, y, x)\n",
    "])\n",
    "#[82:121,1171:1448,1263:1545]\n",
    "rectangle_sm=np.array([\n",
    "    [83, 1171, 1263],  # Premier coin (z, y, x)\n",
    "    [83, 1448, 1263],  # Deuxième coin (z, y, x)\n",
    "    [83,1448 ,1545]   # Troisième coin (z, y, x)\n",
    "])\n",
    "z_interval=(82,121)\n",
    "image=image_cropping_task(image=image,rectangle=rectangle_sm,crop_z=z_interval)\n",
    "rectangle_image=image\n",
    "# scale image\n",
    "new_voxel_size=(None,None,None)\n",
    "#image=set_voxel_size_task(image,new_voxel_size)\n",
    "\n",
    "# Normalise\n",
    "\n",
    "\n",
    "# Gaussian smoothing, change sigma\n",
    "sigma=2.5\n",
    "image=gaussian_smoothing_task(image=image,sigma=sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: P [MainThread] 2025-02-28 10:01:45,452 plantseg.functionals.prediction.prediction - Zoo prediction: Running model from PlantSeg official zoo.\n",
      "INFO: P [MainThread] 2025-02-28 10:01:45,683 plantseg.functionals.prediction.prediction - Computing theoretical minimum halo from model.\n",
      "INFO: P [MainThread] 2025-02-28 10:01:45,685 plantseg.functionals.prediction.prediction - For raw in shape (39, 277, 282): set patch shape (39, 277, 282), set halo shape (0, 0, 0)\n",
      "INFO: P [MainThread] 2025-02-28 10:01:45,686 plantseg.functionals.prediction.utils.array_predictor - Using batch size of 1 for prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: P [MainThread] 2025-02-28 10:01:52,816 plantseg.tasks.segmentation_tasks - The input image is not a boundary probability map. The task will still attempt to run, but the results may not be as expected.\n"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.prediction_tasks import unet_prediction_task\n",
    "from plantseg.tasks.segmentation_tasks import dt_watershed_task, clustering_segmentation_task, lmc_segmentation_task\n",
    "\n",
    "# Segmentation / Prediction\n",
    "model='lightsheet_3D_unet_mouse_embryo_cells' #generic_light_sheet_3D_unet or lightsheet_3D_unet_mouse_embryo_cells or zebrafish\n",
    "model_id=None\n",
    "device= 'cpu' # cpu or cuda\n",
    "image=unet_prediction_task(image=image,model_id=model_id,model_name=model,device=device)[-1]\n",
    "prediction_image=image\n",
    "\n",
    "\n",
    "# Watershed task\n",
    "threshold=0.5 # default 0.5\n",
    "sigma_seeds=0.2 # default 1.0\n",
    "stacked= False # default False \n",
    "sigma_weights=0 # default 2.0\n",
    "min_size=100 # default 100\n",
    "alpha= 1.25 # default 1.0\n",
    "pixel_pitch= None # default None\n",
    "apply_nonmax_suppression= True # default False\n",
    "image=dt_watershed_task(image=image, \n",
    "                        threshold=threshold, \n",
    "                        sigma_seeds=sigma_seeds,\n",
    "                        stacked=stacked, \n",
    "                        sigma_weights=sigma_weights, \n",
    "                        min_size=min_size, \n",
    "                        alpha=alpha, \n",
    "                        pixel_pitch=pixel_pitch, \n",
    "                        apply_nonmax_suppression=apply_nonmax_suppression)\n",
    "\n",
    "\n",
    "\n",
    "# Cluster segmentation task\n",
    "over_segmentation = image # over-segementation image\n",
    "mode = 'gasp' # gasp, multicut or mutex_ws\n",
    "beta = 1.0 # default 0.5\n",
    "post_min_size = 100 # default 100\n",
    "image=clustering_segmentation_task(image=rectangle_image,\n",
    "                                   over_segmentation=\n",
    "                                   over_segmentation,\n",
    "                                   mode=mode,\n",
    "                                   beta=beta,\n",
    "                                   post_min_size=post_min_size)\n",
    "\n",
    "# Lifted Multicut task\n",
    "boundary_pmap=None # cell boundart prediction (Z,Y,X) normalised\n",
    "superpixels=None # superpixels/over-segmentation. Must have the same shape as boundary_pmap.\n",
    "nuclei=None # a nuclear segmentation or prediction map. Must have the same shape as boundary_pmap.\n",
    "beta=None # default 0.5\n",
    "post_min_size=None # default 100\n",
    "\n",
    "#image=lmc_segmentation_task(boundary_pmap: PlantSegImage, superpixels: PlantSegImage, nuclei: PlantSegImage, beta: float = 0.5, post_min_size: int = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 4023.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: P [MainThread] 2025-02-28 10:22:55,471 plantseg.tasks.dataprocessing_tasks - Processing t0001_ch1_cropped_gasp_fg_filtered with shape (39, 277, 282) and max 233, min 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.dataprocessing_tasks import remove_false_positives_by_foreground_probability_task,fix_over_under_segmentation_from_nuclei_task,set_biggest_instance_to_zero_task\n",
    "\n",
    "# Remove false positive\n",
    "segmentation=image # input segmentation\n",
    "foreground=prediction_image # input foreground probability\n",
    "threshold=0.1 # threshold value , DEfault 0.5 \n",
    "image=remove_false_positives_by_foreground_probability_task(segmentation=segmentation, \n",
    "                                                            foreground=foreground, \n",
    "                                                            threshold=threshold)\n",
    "\n",
    "# Fix Over/Under segmentation \n",
    "cell_seg=None # Input cell segmentation \n",
    "nuclei_seg=None # Input nuclear segmentation\n",
    "threshold_merge=None # Threshold for merging cells, as a fraction (0-1)\n",
    "threshold_split=None # Threshold for splitting cells, as a fraction (0-1)\n",
    "quantile_min=None # Minimum quantile for filtering nuclei sizes, as a fraction (0-1)\n",
    "quantile_max=None # Maximum quantile for filtering nuclei sizes, as a fraction (0-1)\n",
    "boundary=None # Optional boundary probability map for segmentation refinement, default None\n",
    "#image=fix_over_under_segmentation_from_nuclei_task(cell_seg=cell_seg, \n",
    "#                                                   nuclei_seg=nuclei_seg, \n",
    "#                                                   threshold_merge=threshold_merge, \n",
    "#                                                   threshold_split=threshold_merge, \n",
    "#                                                   quantile_min=quantile_min, \n",
    "#                                                   quantile_max=quantile_max, \n",
    "#                                                   boundary=boundary)\n",
    "\n",
    "# Set biggest object as background task\n",
    "instance_could_be_zero=False # default False, If True, 0 might be an instance label, add 1 to all labels before processing\n",
    "image=set_biggest_instance_to_zero_task(image=image,instance_could_be_zero=instance_could_be_zero)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.tasks.io_tasks import export_image_task \n",
    "\n",
    "#Export\n",
    "export_directory=Path(r\"E:\\PROJECTS-01\\Adrian\\Bachelor_project\\postprocessed_data\\gausse25\") #  output directory path where the image will be save\n",
    "name_pattern=\"t0001_ch1_1\" #  default '{file_name}_export', output file name pattern\n",
    "key=None # default None, key for the image (used only for h5 and zarr formats)\n",
    "scale_to_origin=True # default True, scale the voxel size to the original one\n",
    "export_format='tiff' # 'tiff', 'h5' or 'zarr'\n",
    "data_type='uint16' #  default 'uint16'\n",
    "export_image_task(image=image,\n",
    "                  export_directory=export_directory,\n",
    "                  name_pattern=name_pattern,\n",
    "                  key=key,\n",
    "                  scale_to_origin=scale_to_origin,\n",
    "                  export_format=export_format,\n",
    "                  data_type=data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant-seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
