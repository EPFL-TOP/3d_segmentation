{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running plantseg\n",
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: P [MainThread] 2025-05-27 13:09:09,419 plantseg - Logger configured at initialisation. PlantSeg logger name: plantseg\n"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.io_tasks import import_image_task\n",
    "from pathlib import Path\n",
    "\n",
    "'''\n",
    "The Plantseg documentation can be found at:\n",
    "https://github.com/kreshuklab/plant-seg/tree/master\n",
    "https://kreshuklab.github.io/plant-seg/\n",
    "'''\n",
    "\n",
    "# Transform image into PlantsegImage\n",
    "path=Path(r\"/mnt/e/PROJECTS-01/Adrian/Bachelor_project/Raw_data/t0001_ch1.tif\")\n",
    "semantic_type=\"raw\" # options are 'raw', 'segmentation' and 'prediction'\n",
    "stack_layout= \"ZYX\" # options are 'ZYX', 'YX', '2D_time'\n",
    "image=import_image_task(input_path=path,semantic_type=semantic_type,stack_layout=stack_layout)\n",
    "raw_image=image #usefull for later tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.tasks.dataprocessing_tasks import image_cropping_task,set_voxel_size_task,gaussian_smoothing_task\n",
    "import numpy as np\n",
    "\n",
    "# Cropping, change intervals to what you need\n",
    "#[77:195,437:1446,654:]\n",
    "rectangle_bi= np.array([\n",
    "    [77, 437, 654],  # Premier coin (z, y, x)\n",
    "    [77, 1446, 654],  # Deuxième coin (z, y, x)\n",
    "    [77,1446 ,2304]   # Troisième coin (z, y, x)\n",
    "])\n",
    "z_interval_bi=(77,195)\n",
    "\n",
    "#[82:121,1171:1448,1263:1545]\n",
    "rectangle_sm=np.array([\n",
    "    [83, 1171, 1263],  # Premier coin (z, y, x)\n",
    "    [83, 1448, 1263],  # Deuxième coin (z, y, x)\n",
    "    [83,1448 ,1545]   # Troisième coin (z, y, x)\n",
    "])\n",
    "z_interval_sm=(82,121)\n",
    "\n",
    "image=image_cropping_task(image=raw_image,rectangle=rectangle_bi,crop_z=z_interval_bi)\n",
    "rectangle_image=image\n",
    "\n",
    "# scale image\n",
    "'''x,y,z pixel size = 0.347,0.347,0.5 microns'''\n",
    "voxel_size=(0.5,0.347,0.347)\n",
    "image=set_voxel_size_task(image=image,voxel_size=voxel_size)\n",
    "\n",
    "\n",
    "# Gaussian smoothing, change sigma\n",
    "sigma=2.0\n",
    "image=gaussian_smoothing_task(image=image,sigma=sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: P [MainThread] 2025-05-27 13:10:11,955 plantseg.functionals.prediction.prediction - Safari prediction: Running model from custom config path.\n",
      "INFO: P [MainThread] 2025-05-27 13:10:13,004 plantseg.functionals.prediction.prediction - Computing theoretical minimum halo from model.\n",
      "INFO: P [MainThread] 2025-05-27 13:10:13,008 plantseg.functionals.prediction.prediction - For raw in shape (118, 1009, 1650): set patch shape (32, 128, 128), set halo shape (92, 92, 92)\n",
      "INFO: P [MainThread] 2025-05-27 13:10:13,009 plantseg.functionals.prediction.utils.array_predictor - Using batch size of 1 for prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 935/935 [4:49:54<00:00, 18.60s/it]  \n"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.prediction_tasks import unet_prediction_task\n",
    "from plantseg.tasks.segmentation_tasks import dt_watershed_task, clustering_segmentation_task, lmc_segmentation_task\n",
    "\n",
    "# Segmentation / Prediction\n",
    "model='generic_light_sheet_3D_unet' #generic_light_sheet_3D_unet or lightsheet_3D_unet_mouse_embryo_cells\n",
    "model_id=None\n",
    "device= 'cpu' # cpu or cuda (using cuda makes the hive crash, so use cpu for now)\n",
    "image=unet_prediction_task(image=image,model_id=model_id,model_name=model,device=device)[-1] # [-1] because returns a list of images, the last one is the prediction\n",
    "\n",
    "\n",
    "# Prediction with a trained model\n",
    "config_path=Path(\"/mnt/e/PROJECTS-01/Adrian/Bachelor_project/code/Train/config.yml\")\n",
    "model_weights_path=Path(\"/mnt/e/PROJECTS-01/Adrian/Bachelor_project/Train/model/last_checkpoint03.pytorch\")\n",
    "patch=(32, 128, 128) # patch size for the model (same as used for training)\n",
    "'''\n",
    "image=unet_prediction_task(\n",
    "    image=image,\n",
    "    model_name=None,\n",
    "    model_id=None,\n",
    "    config_path=config_path,\n",
    "    model_weights_path=model_weights_path,\n",
    "    patch=patch,\n",
    "    device=\"cpu\")[-1]\n",
    "'''\n",
    "\n",
    "prediction_image=image # usefull for later tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer, image_layer = napari.imshow(image._data) #image._data is the numpy array of the image (PlantsegImage)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.tasks.segmentation_tasks import dt_watershed_task\n",
    "\n",
    "threshold=0.5 # default 0.5\n",
    "sigma_seeds=0.2 # default 1.0\n",
    "stacked= False # default False, If True and the image is 3D, processes the image slice-by-slice (2D)\n",
    "sigma_weights=0 # default 2.0\n",
    "min_size=100 # default 100\n",
    "alpha= 0.8 # default 1.0\n",
    "pixel_pitch= (1.441,1,1) # default None\n",
    "apply_nonmax_suppression= True # default False\n",
    "image=dt_watershed_task(image=prediction_image, \n",
    "                        threshold=threshold, \n",
    "                        sigma_seeds=sigma_seeds,\n",
    "                        stacked=stacked, \n",
    "                        sigma_weights=sigma_weights, \n",
    "                        min_size=min_size, \n",
    "                        alpha=alpha, \n",
    "                        pixel_pitch=pixel_pitch, \n",
    "                        apply_nonmax_suppression=apply_nonmax_suppression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: P [MainThread] 2025-03-04 16:50:25,088 plantseg.tasks.segmentation_tasks - The input image is not a boundary probability map. The task will still attempt to run, but the results may not be as expected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrifern/miniforge3/envs/plant-seg/lib/python3.12/site-packages/elf/segmentation/multicut.py:68: RuntimeWarning: divide by zero encountered in log\n",
      "  costs = np.log((1. - costs) / costs) + np.log((1. - beta) / beta)\n"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.segmentation_tasks import clustering_segmentation_task, lmc_segmentation_task\n",
    "\n",
    "over_segmentation = image # over-segementation image\n",
    "mode = 'gasp' # gasp, multicut or mutex_ws\n",
    "beta = 1.0 # default 0.5\n",
    "post_min_size = 100 # default 100\n",
    "image=clustering_segmentation_task(image=rectangle_image,\n",
    "                                   over_segmentation=over_segmentation,\n",
    "                                   mode=mode,\n",
    "                                   beta=beta,\n",
    "                                   post_min_size=post_min_size)\n",
    "\n",
    "\n",
    "# Lifted Multicut task if nuclei segmentation is available\n",
    "\n",
    "boundary_pmap=None # cell boundart prediction (Z,Y,X) normalised\n",
    "superpixels=None # superpixels/over-segmentation. Must have the same shape as boundary_pmap.\n",
    "nuclei=None # a nuclear segmentation or prediction map. Must have the same shape as boundary_pmap.\n",
    "beta=None # default 0.5\n",
    "post_min_size=None # default 100\n",
    "#image=lmc_segmentation_task(boundary_pmap: PlantSegImage, superpixels: PlantSegImage, nuclei: PlantSegImage, beta: float = 0.5, post_min_size: int = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 4023.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: P [MainThread] 2025-02-28 10:22:55,471 plantseg.tasks.dataprocessing_tasks - Processing t0001_ch1_cropped_gasp_fg_filtered with shape (39, 277, 282) and max 233, min 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.dataprocessing_tasks import remove_false_positives_by_foreground_probability_task,fix_over_under_segmentation_from_nuclei_task,set_biggest_instance_to_zero_task\n",
    "\n",
    "# Remove false positive\n",
    "segmentation=image # input segmentation\n",
    "foreground=prediction_image # input foreground probability\n",
    "threshold=0.1 # threshold value , DEfault 0.5 \n",
    "image=remove_false_positives_by_foreground_probability_task(segmentation=segmentation, \n",
    "                                                            foreground=foreground, \n",
    "                                                            threshold=threshold)\n",
    "\n",
    "# Fix Over/Under segmentation \n",
    "cell_seg=None # Input cell segmentation \n",
    "nuclei_seg=None # Input nuclear segmentation\n",
    "threshold_merge=None # Threshold for merging cells, as a fraction (0-1)\n",
    "threshold_split=None # Threshold for splitting cells, as a fraction (0-1)\n",
    "quantile_min=None # Minimum quantile for filtering nuclei sizes, as a fraction (0-1)\n",
    "quantile_max=None # Maximum quantile for filtering nuclei sizes, as a fraction (0-1)\n",
    "boundary=None # Optional boundary probability map for segmentation refinement, default None\n",
    "image=fix_over_under_segmentation_from_nuclei_task(cell_seg=cell_seg, \n",
    "                                                   nuclei_seg=nuclei_seg, \n",
    "                                                   threshold_merge=threshold_merge, \n",
    "                                                   threshold_split=threshold_merge, \n",
    "                                                   quantile_min=quantile_min, \n",
    "                                                   quantile_max=quantile_max, \n",
    "                                                   boundary=boundary)\n",
    "\n",
    "# Set biggest object as background task\n",
    "instance_could_be_zero=False # default False, If True, 0 might be an instance label, add 1 to all labels before processing\n",
    "image=set_biggest_instance_to_zero_task(image=image,instance_could_be_zero=instance_could_be_zero)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.tasks.io_tasks import export_image_task \n",
    "\n",
    "#Export\n",
    "export_directory=Path(r\"E:\\PROJECTS-01\\Adrian\\Bachelor_project\\postprocessed_data\\gauss25\") #  output directory path where the image will be save\n",
    "name_pattern=\"t0001_ch1_1\" #  default '{file_name}_export', output file name pattern\n",
    "key=None # default None, key for the image (used only for h5 and zarr formats)\n",
    "scale_to_origin=True # default True, scale the voxel size to the original one\n",
    "export_format='tiff' # 'tiff', 'h5' or 'zarr'\n",
    "data_type='uint16' #  default 'uint16'\n",
    "export_image_task(image=image,\n",
    "                  export_directory=export_directory,\n",
    "                  name_pattern=name_pattern,\n",
    "                  key=key,\n",
    "                  scale_to_origin=scale_to_origin,\n",
    "                  export_format=export_format,\n",
    "                  data_type=data_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant-seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
